{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files_example = os.listdir(\"data_example\")\n",
    "data_list = {}\n",
    "\n",
    "for i, file in enumerate(list_files_example):\n",
    "    if file != \".DS_Store\":\n",
    "        with open(\"data_example/\" + file) as f:\n",
    "            data_list[i] = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_json_data_to_dataframe(json_data):\n",
    "    data_field = json_data[\"data\"]\n",
    "    # Split fields in timestamp & value\n",
    "    df_exploration = pd.DataFrame(list(map(lambda x: x.split(\" \"), data_field)), \n",
    "                                  columns= [\"timestamp\", \"RrInterval\"])\n",
    "\n",
    "    # Cast value as int\n",
    "    df_exploration[\"RrInterval\"] = df_exploration[\"RrInterval\"].apply(lambda x : int(x))\n",
    "\n",
    "    # set cleaned timestamp as index\n",
    "    df_exploration[\"timestamp\"] = pd.to_datetime(df_exploration[\"timestamp\"])\n",
    "    df_exploration = df_exploration.set_index(\"timestamp\")\n",
    "\n",
    "    return df_exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration de la cohérence des données extraites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fichier 0\n",
      "Somme des RrInt (s): 1003.24\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:20.892000\n",
      "En secondes : 1040\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-05 16:14:00          41\n",
      "2018-07-05 16:15:00          57\n",
      "2018-07-05 16:16:00          60\n",
      "2018-07-05 16:17:00          60\n",
      "2018-07-05 16:18:00          59\n",
      "2018-07-05 16:19:00          59\n",
      "2018-07-05 16:20:00          59\n",
      "2018-07-05 16:21:00          60\n",
      "2018-07-05 16:22:00          58\n",
      "2018-07-05 16:23:00          61\n",
      "2018-07-05 16:24:00          58\n",
      "2018-07-05 16:25:00          56\n",
      "2018-07-05 16:26:00          61\n",
      "2018-07-05 16:27:00          59\n",
      "2018-07-05 16:28:00          55\n",
      "2018-07-05 16:29:00          52\n",
      "2018-07-05 16:30:00          49\n",
      "2018-07-05 16:31:00          36\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 1\n",
      "Problem for data_list[1]\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 2\n",
      "Somme des RrInt (s): 718.438\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.998000\n",
      "En secondes : 998\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-03 12:58:00           1\n",
      "2018-07-03 12:59:00          60\n",
      "2018-07-03 13:00:00          60\n",
      "2018-07-03 13:01:00          60\n",
      "2018-07-03 13:02:00          60\n",
      "2018-07-03 13:03:00          60\n",
      "2018-07-03 13:04:00          60\n",
      "2018-07-03 13:05:00          60\n",
      "2018-07-03 13:06:00          60\n",
      "2018-07-03 13:07:00          60\n",
      "2018-07-03 13:08:00          60\n",
      "2018-07-03 13:09:00          60\n",
      "2018-07-03 13:10:00          60\n",
      "2018-07-03 13:11:00          60\n",
      "2018-07-03 13:12:00          60\n",
      "2018-07-03 13:13:00          60\n",
      "2018-07-03 13:14:00          60\n",
      "2018-07-03 13:15:00          39\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 3\n",
      "Problem for data_list[3]\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 4\n",
      "Somme des RrInt (s): 1062.46\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:44.880000\n",
      "En secondes : 1064\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-05 15:15:00           5\n",
      "2018-07-05 15:16:00          58\n",
      "2018-07-05 15:17:00          58\n",
      "2018-07-05 15:18:00          56\n",
      "2018-07-05 15:19:00          55\n",
      "2018-07-05 15:20:00          53\n",
      "2018-07-05 15:21:00          59\n",
      "2018-07-05 15:22:00          52\n",
      "2018-07-05 15:23:00          58\n",
      "2018-07-05 15:24:00          59\n",
      "2018-07-05 15:25:00          57\n",
      "2018-07-05 15:26:00          54\n",
      "2018-07-05 15:27:00          55\n",
      "2018-07-05 15:28:00          56\n",
      "2018-07-05 15:29:00          57\n",
      "2018-07-05 15:30:00          55\n",
      "2018-07-05 15:31:00          58\n",
      "2018-07-05 15:32:00          58\n",
      "2018-07-05 15:33:00          37\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 5\n",
      "Somme des RrInt (s): 1091.562\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:20:41.052000\n",
      "En secondes : 1241\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-05 15:36:00          31\n",
      "2018-07-05 15:37:00          54\n",
      "2018-07-05 15:38:00          57\n",
      "2018-07-05 15:39:00          55\n",
      "2018-07-05 15:40:00          53\n",
      "2018-07-05 15:41:00          57\n",
      "2018-07-05 15:42:00          58\n",
      "2018-07-05 15:43:00          55\n",
      "2018-07-05 15:44:00          54\n",
      "2018-07-05 15:45:00          57\n",
      "2018-07-05 15:46:00          54\n",
      "2018-07-05 15:47:00          54\n",
      "2018-07-05 15:48:00          56\n",
      "2018-07-05 15:49:00          51\n",
      "2018-07-05 15:50:00           4\n",
      "2018-07-05 15:51:00           0\n",
      "2018-07-05 15:52:00          27\n",
      "2018-07-05 15:53:00          56\n",
      "2018-07-05 15:54:00          54\n",
      "2018-07-05 15:55:00          51\n",
      "2018-07-05 15:56:00          53\n",
      "2018-07-05 15:57:00           9\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 6\n",
      "Somme des RrInt (s): 782.054\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.868000\n",
      "En secondes : 998\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-05 16:00:00          14\n",
      "2018-07-05 16:01:00          60\n",
      "2018-07-05 16:02:00          60\n",
      "2018-07-05 16:03:00          59\n",
      "2018-07-05 16:04:00          60\n",
      "2018-07-05 16:05:00          60\n",
      "2018-07-05 16:06:00          59\n",
      "2018-07-05 16:07:00          61\n",
      "2018-07-05 16:08:00          60\n",
      "2018-07-05 16:09:00          60\n",
      "2018-07-05 16:10:00          60\n",
      "2018-07-05 16:11:00          61\n",
      "2018-07-05 16:12:00          60\n",
      "2018-07-05 16:13:00          60\n",
      "2018-07-05 16:14:00          60\n",
      "2018-07-05 16:15:00          60\n",
      "2018-07-05 16:16:00          59\n",
      "2018-07-05 16:17:00          27\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 7\n",
      "Somme des RrInt (s): 718.248\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.858000\n",
      "En secondes : 998\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-03 16:02:00          50\n",
      "2018-07-03 16:03:00          60\n",
      "2018-07-03 16:04:00          60\n",
      "2018-07-03 16:05:00          60\n",
      "2018-07-03 16:06:00          60\n",
      "2018-07-03 16:07:00          59\n",
      "2018-07-03 16:08:00          61\n",
      "2018-07-03 16:09:00          60\n",
      "2018-07-03 16:10:00          60\n",
      "2018-07-03 16:11:00          60\n",
      "2018-07-03 16:12:00          60\n",
      "2018-07-03 16:13:00          60\n",
      "2018-07-03 16:14:00          60\n",
      "2018-07-03 16:15:00          60\n",
      "2018-07-03 16:16:00          60\n",
      "2018-07-03 16:17:00          60\n",
      "2018-07-03 16:18:00          50\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 8\n",
      "Somme des RrInt (s): 949.277\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:39.917000\n",
      "En secondes : 999\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-06 15:01:00          23\n",
      "2018-07-06 15:02:00          60\n",
      "2018-07-06 15:03:00          61\n",
      "2018-07-06 15:04:00          59\n",
      "2018-07-06 15:05:00          60\n",
      "2018-07-06 15:06:00          61\n",
      "2018-07-06 15:07:00          59\n",
      "2018-07-06 15:08:00          59\n",
      "2018-07-06 15:09:00          60\n",
      "2018-07-06 15:10:00          60\n",
      "2018-07-06 15:11:00          60\n",
      "2018-07-06 15:12:00          60\n",
      "2018-07-06 15:13:00          60\n",
      "2018-07-06 15:14:00          60\n",
      "2018-07-06 15:15:00          60\n",
      "2018-07-06 15:16:00          60\n",
      "2018-07-06 15:17:00          60\n",
      "2018-07-06 15:18:00          18\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 9\n",
      "Somme des RrInt (s): 1034.512\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:20.893000\n",
      "En secondes : 1040\n",
      "                     RrInterval\n",
      "timestamp                      \n",
      "2018-07-06 14:40:00          22\n",
      "2018-07-06 14:41:00          59\n",
      "2018-07-06 14:42:00          57\n",
      "2018-07-06 14:43:00          57\n",
      "2018-07-06 14:44:00          56\n",
      "2018-07-06 14:45:00          58\n",
      "2018-07-06 14:46:00          59\n",
      "2018-07-06 14:47:00          59\n",
      "2018-07-06 14:48:00          59\n",
      "2018-07-06 14:49:00          60\n",
      "2018-07-06 14:50:00          58\n",
      "2018-07-06 14:51:00          59\n",
      "2018-07-06 14:52:00          58\n",
      "2018-07-06 14:53:00          58\n",
      "2018-07-06 14:54:00          57\n",
      "2018-07-06 14:55:00          57\n",
      "2018-07-06 14:56:00          52\n",
      "2018-07-06 14:57:00          55\n",
      "\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_list)):\n",
    "    try:\n",
    "        print()\n",
    "        print(\"fichier {}\".format(i))\n",
    "        df = transform_json_data_to_dataframe(data_list[i])\n",
    "        print(\"Somme des RrInt (s): \" + str(df[\"RrInterval\"].sum() / 1000))\n",
    "        print(\"Nombre de RrInt : \" + str(df[\"RrInterval\"].count()))\n",
    "        timedelta = df.index[-1] - df.index[0]\n",
    "        print(\"TimeDelta : \" + str(timedelta))\n",
    "        print(\"En secondes : \" + str(timedelta.seconds))\n",
    "        print(df.resample(\"1T\").count())\n",
    "        print()\n",
    "        print(\"------------------------------------\")\n",
    "    except:\n",
    "        print(\"Problem for \" + \"data_list[\" + str(i) + \"]\")\n",
    "        print()\n",
    "        print(\"------------------------------------\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data_list)):\n",
    "    try:\n",
    "        df = transform_json_data_to_dataframe(data_list[i])\n",
    "        df.plot(figsize=(10, 6), title=\"fichier {}\".format(i))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration de l'impact des méthodes de suppression d'outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_outlier(rr_intervals, low_rri=300, high_rri=2000):\n",
    "    \"\"\"\n",
    "    Function that replace RR Interval outlier by nan\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    rr_intervals:\n",
    "    low_rri:\n",
    "    high_rri:\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    rr_intervals_cleaned - list of RR Intervals without outliers\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Conversion RrInterval / Heart rate ==> rri (ms) =  1000 / (bpm / 60)\n",
    "    # rri 2000 => bpm 30 / rri 300 => bpm 200\n",
    "    rr_intervals_cleaned = [x if high_rri >= x >= low_rri else np.nan for x in rr_intervals]\n",
    "    nan_count = sum(np.isnan(rr_intervals_cleaned))\n",
    "    print(\"{} outlier(s) have been deleted.\".format(nan_count))\n",
    "    return rr_intervals_cleaned\n",
    "\n",
    "def interpolate_cleaned_outlier(rr_intervals_cleaned):\n",
    "    \"\"\"\n",
    "    Function that interpolate Nan values with linear interpolation\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    rr_intervals_cleaned:\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    rr_intervals_interpolated\n",
    "    \"\"\"\n",
    "    s = pd.Series(rr_intervals_cleaned)\n",
    "    rr_intervals_interpolated = s.interpolate(method=\"linear\")\n",
    "    return rr_intervals_interpolated\n",
    "\n",
    "\n",
    "def clean_ectopic_beats(rr_intervals, method=\"Malik\", custom_rule=None):\n",
    "    \"\"\"\n",
    "    RR intervals differing by more than the removing_rule from the one proceeding it are removed.\n",
    "\n",
    "    Arguments\n",
    "    ---------\n",
    "    rr_intervals - list of Rr Intervals\n",
    "    method - method to use to clean outlier. Malik, Kamath, Karlsson, mean_last9 or Custom\n",
    "    custom_rule - percentage criteria of difference with previous Rr\n",
    "    Interval at which we consider that it is abnormal\n",
    "\n",
    "    Returns\n",
    "    ---------\n",
    "    nn_intervals - list of NN Interval\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # set first element in list\n",
    "    nn_intervals = [rr_intervals[0]]\n",
    "    outlier_count = 0\n",
    "    previous_outlier = False\n",
    "\n",
    "    # if method == \"Karlsson\":\n",
    "    #     if i == len(rr_intervals)-2:\n",
    "    #         break\n",
    "    #     mean_prev_next_rri = (rr_interval + rr_intervals[i + 2]) / 2\n",
    "    #     if abs(mean_prev_next_rri - rr_intervals[i+1]) < 0.2 * mean_prev_next_rri:\n",
    "    #         nn_intervals.append(rr_intervals[i+1])\n",
    "    #     else:\n",
    "    #         nn_intervals.append(np.nan)\n",
    "    #         outlier_count += 1\n",
    "    #         previous_outlier = True\n",
    "    #\n",
    "    # return nn_intervals\n",
    "\n",
    "    if method == \"mean_last9\":\n",
    "        nn_intervals = []\n",
    "        for i, rr_interval in enumerate(rr_intervals):\n",
    "\n",
    "            if i < 9:\n",
    "                nn_intervals.append(rr_interval)\n",
    "                continue\n",
    "\n",
    "            mean_last_9_elt = np.nanmean(nn_intervals[-9:])\n",
    "            if abs(mean_last_9_elt - rr_interval) < 0.3 * mean_last_9_elt:\n",
    "                nn_intervals.append(rr_interval)\n",
    "            else:\n",
    "                nn_intervals.append(np.nan)\n",
    "                outlier_count += 1\n",
    "                # previous_outlier = True\n",
    "    else:\n",
    "        for i, rr_interval in enumerate(rr_intervals[:-1]):\n",
    "\n",
    "            if previous_outlier:\n",
    "                nn_intervals.append(rr_intervals[i + 1])\n",
    "                previous_outlier = False\n",
    "                continue\n",
    "\n",
    "            # TO DO pour v2 ... Check si plusieurs outliers consécutifs. Quelle règle appliquer ?\n",
    "            # while previous_outlier:\n",
    "            #   j += 1\n",
    "            #  if is_outlier(rr_interval, rr_intervals[i+1+j]):\n",
    "            #     nn_intervals.append(np.nan)\n",
    "            #    continue\n",
    "            # else:\n",
    "            #    previous_outlier = False\n",
    "\n",
    "            if is_outlier(rr_interval, rr_intervals[i + 1], method=method, custom_rule=custom_rule):\n",
    "                nn_intervals.append(rr_intervals[i + 1])\n",
    "            else:\n",
    "                # A débattre, Comment remplacer les outliers ?\n",
    "                nn_intervals.append(np.nan)\n",
    "                outlier_count += 1\n",
    "                previous_outlier = True\n",
    "\n",
    "    print(\"{} ectopic beat(s) have been deleted with {} rule.\".format(outlier_count, method))\n",
    "\n",
    "    return nn_intervals\n",
    "\n",
    "\n",
    "def is_outlier(rr_interval, next_rr_interval, method=\"Malik\", custom_rule=None):\n",
    "    if method == \"Malik\":\n",
    "        return abs(rr_interval - next_rr_interval) <= 0.2 * rr_interval\n",
    "    elif method == \"Kamath\":\n",
    "        return 0 <= (next_rr_interval - rr_interval) <= 0.325 * rr_interval or 0 <= (rr_interval - next_rr_interval) \\\n",
    "               <= 0.245 * rr_interval\n",
    "    elif method == \"custom\":\n",
    "        return abs(rr_interval - next_rr_interval) <= custom_rule * rr_interval\n",
    "    else:\n",
    "        raise ValueError(\"Not a valid method. Please choose Malik or Kamath\")\n",
    "\n",
    "\n",
    "def is_valid_sample(nn_intervals, outlier_count, removing_rule=0.04):\n",
    "    \"\"\"\n",
    "    Test if the sample meet the condition to be used for analysis\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    nn_intervals - list of Normal to Normal Interval\n",
    "    outlier_count - count of outliers or ectopic beats removed from the interval\n",
    "    removing_rule - rule to follow to determine whether the sample is valid or not\n",
    "\n",
    "    Returns\n",
    "    ----------\n",
    "    Boolean - True if sample is valid, False if not\n",
    "    \"\"\"\n",
    "    if outlier_count / len(nn_intervals) > removing_rule:\n",
    "        print(\"Too much outlier for analyses ! You should descard the sample\")\n",
    "        return  False\n",
    "    if len(nn_intervals) < 240:\n",
    "        print(\"Not enough Heart beat for Nyquist criteria ! \")\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fichier 0\n",
      "Somme des RrInt (s): 1003.24\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:20.892000\n",
      "En secondes : 1040\n",
      "0 outlier(s) have been deleted.\n",
      "21 ectopic beat(s) have been deleted with Malik rule.\n",
      "9 ectopic beat(s) have been deleted with Kamath rule.\n",
      "10 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 1\n",
      "Problem for data_list[1]\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 2\n",
      "Somme des RrInt (s): 718.438\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.998000\n",
      "En secondes : 998\n",
      "0 outlier(s) have been deleted.\n",
      "2 ectopic beat(s) have been deleted with Malik rule.\n",
      "0 ectopic beat(s) have been deleted with Kamath rule.\n",
      "0 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 3\n",
      "Problem for data_list[3]\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 4\n",
      "Somme des RrInt (s): 1062.46\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:44.880000\n",
      "En secondes : 1064\n",
      "0 outlier(s) have been deleted.\n",
      "41 ectopic beat(s) have been deleted with Malik rule.\n",
      "10 ectopic beat(s) have been deleted with Kamath rule.\n",
      "5 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 5\n",
      "Somme des RrInt (s): 1091.562\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:20:41.052000\n",
      "En secondes : 1241\n",
      "0 outlier(s) have been deleted.\n",
      "28 ectopic beat(s) have been deleted with Malik rule.\n",
      "7 ectopic beat(s) have been deleted with Kamath rule.\n",
      "6 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 6\n",
      "Somme des RrInt (s): 782.054\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.868000\n",
      "En secondes : 998\n",
      "0 outlier(s) have been deleted.\n",
      "1 ectopic beat(s) have been deleted with Malik rule.\n",
      "1 ectopic beat(s) have been deleted with Kamath rule.\n",
      "2 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 7\n",
      "Somme des RrInt (s): 718.248\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:38.858000\n",
      "En secondes : 998\n",
      "0 outlier(s) have been deleted.\n",
      "0 ectopic beat(s) have been deleted with Malik rule.\n",
      "0 ectopic beat(s) have been deleted with Kamath rule.\n",
      "0 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 8\n",
      "Somme des RrInt (s): 949.277\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:16:39.917000\n",
      "En secondes : 999\n",
      "0 outlier(s) have been deleted.\n",
      "0 ectopic beat(s) have been deleted with Malik rule.\n",
      "0 ectopic beat(s) have been deleted with Kamath rule.\n",
      "0 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n",
      "\n",
      "fichier 9\n",
      "Somme des RrInt (s): 1034.512\n",
      "Nombre de RrInt : 1000\n",
      "TimeDelta : 0 days 00:17:20.893000\n",
      "En secondes : 1040\n",
      "1 outlier(s) have been deleted.\n",
      "7 ectopic beat(s) have been deleted with Malik rule.\n",
      "2 ectopic beat(s) have been deleted with Kamath rule.\n",
      "137 ectopic beat(s) have been deleted with mean_last9 rule.\n",
      "\n",
      "------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/robinchampseix/Desktop/stage/features_engineering/venv/lib/python3.7/site-packages/ipykernel_launcher.py:84: RuntimeWarning: Mean of empty slice\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data_list)):\n",
    "    try:\n",
    "        print()\n",
    "        print(\"fichier {}\".format(i))\n",
    "        df = transform_json_data_to_dataframe(data_list[i])\n",
    "        print(\"Somme des RrInt (s): \" + str(df[\"RrInterval\"].sum() / 1000))\n",
    "        print(\"Nombre de RrInt : \" + str(df[\"RrInterval\"].count()))\n",
    "        timedelta = df.index[-1] - df.index[0]\n",
    "        print(\"TimeDelta : \" + str(timedelta))\n",
    "        print(\"En secondes : \" + str(timedelta.seconds))\n",
    "        # Clean Outlier Method\n",
    "        df_cleaned = clean_outlier(df[\"RrInterval\"])\n",
    "        # clean ectopic beats\n",
    "        df_malik = clean_ectopic_beats(df[\"RrInterval\"], method=\"Malik\")\n",
    "        df_Kamath = clean_ectopic_beats(df[\"RrInterval\"], method=\"Kamath\")\n",
    "        df_mean_last9 = clean_ectopic_beats(df[\"RrInterval\"], method=\"mean_last9\")\n",
    "        print()\n",
    "        print(\"------------------------------------\")\n",
    "    except:\n",
    "        print(\"Problem for \" + \"data_list[\" + str(i) + \"]\")\n",
    "        print()\n",
    "        print(\"------------------------------------\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
